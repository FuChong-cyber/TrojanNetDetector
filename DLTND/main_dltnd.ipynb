{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import dataset_input\n",
    "import resnet\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import utilities\n",
    "import json\n",
    "from UniversalPerturb import UniversalPert\n",
    "from PerImgPerturb import PerImgPert\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#load the testing data\n",
    "version = sys.version_info\n",
    "def _load_datafile(filename):\n",
    "        with open(filename, 'rb') as fo:\n",
    "            if version.major == 3:\n",
    "                data_dict = pickle.load(fo, encoding='bytes')\n",
    "            else:\n",
    "                data_dict = pickle.load(fo)\n",
    "\n",
    "            assert data_dict[b'data'].dtype == np.uint8\n",
    "            image_data = data_dict[b'data']\n",
    "            image_data = image_data.reshape((10000, 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "            return image_data, np.array(data_dict[b'labels'])\n",
    "eval_filename = 'test_batch'\n",
    "path = \"cifar-10-batches-py\"\n",
    "eval_images, eval_labels = _load_datafile(\n",
    "            os.path.join(path, eval_filename))\n",
    "eval_images = np.reshape(eval_images, (10000, 3072))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "BINARY_SEARCH_STEPS = 12  # number of times to adjust the constant with binary search\n",
    "MAX_ITERATIONS = 101  # number of iterations to perform gradient descent\n",
    "#ABORT_EARLY = True       # if we stop improving, abort gradient descent early\n",
    "LEARNING_RATE = 1e-2     # larger values converge faster to less accurate results\n",
    "INITIAL_CONST = 0.01     # the initial constant lambda to pick as a first guess\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "num_class = 10\n",
    "\n",
    "#randomly select a small amount of data\n",
    "idxx = np.arange(0 , 10000)\n",
    "judge_class = 5*np.ones(10)\n",
    "count_num = 0\n",
    "idx = np.zeros(50, dtype=int)\n",
    "for nn in range(0, num_class):\n",
    "    for ii in idxx:\n",
    "        if judge_class[nn] == 0:\n",
    "            break\n",
    "        if eval_labels[ii] == nn:\n",
    "            idx[count_num] = int(ii)\n",
    "            count_num = count_num + 1\n",
    "            judge_class[nn] = judge_class[nn] - 1\n",
    "\n",
    "\n",
    "\n",
    "data_shuffle = eval_images[idx]\n",
    "labels_shuffle = eval_labels[idx]\n",
    "for jj in range(0,1):\n",
    "    path_new = 'models/'+'clean'+str(jj+1)+'/'\n",
    "\n",
    "\n",
    "    data_num_labels = []\n",
    "    out_save_poison = []\n",
    "    bestarea_cand_pos = []\n",
    "    area_cand_pos = []\n",
    "    out_cand_pos = []\n",
    "    #pos_mul = []\n",
    "    pos_single = []\n",
    "    for targets in range(0, num_class):\n",
    "        tf.reset_default_graph() #avoid the variable reusing\n",
    "        y_tru_val = tf.convert_to_tensor(labels_shuffle)\n",
    "\n",
    "        #find images belonging to the selected label and images that are not\n",
    "        indices = tf.where(tf.not_equal(y_tru_val, targets))\n",
    "        indices2 = tf.where(tf.equal(y_tru_val, targets))\n",
    "        indices = tf.reshape(indices, [-1])\n",
    "        indices2 = tf.reshape(indices2, [-1])\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.initializers.global_variables())\n",
    "            indices = indices.eval()\n",
    "            indices2 = indices2.eval()\n",
    "        #sess.close\n",
    "        batchsize = len(indices)\n",
    "        batchsize2 = len(indices2)\n",
    "        labels_shuffle_new = np.zeros((50, num_class))\n",
    "        labels_shuffle_new[np.arange(50), labels_shuffle] = 1\n",
    "        imgs = data_shuffle[indices]\n",
    "        imgs = imgs.reshape((batchsize, 32, 32, 3))\n",
    "        labs = labels_shuffle_new[indices]\n",
    "        imgs2 = data_shuffle[indices2]\n",
    "        imgs2 = imgs2.reshape((batchsize2, 32, 32, 3))\n",
    "        labs2 = labels_shuffle_new[indices2]\n",
    "        data_num_labels.append(batchsize2)   \n",
    "        image = np.concatenate((imgs, imgs2), axis=0)\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.initializers.global_variables())\n",
    "            regul = \"l1\"\n",
    "            print(\"- regularization is\" + str(regul))\n",
    "            print(\"- trojan pixel, moving label:\\t\\t{}\".format(targets))\n",
    "            config_dict = utilities.get_config('config.json')\n",
    "\n",
    "            model_dir = config_dict['model']['output_dir']\n",
    "            if not os.path.exists(model_dir):\n",
    "                os.makedirs(model_dir)\n",
    "\n",
    "            # keep the configuration file with the model for reproducibility\n",
    "            with open(os.path.join(model_dir, 'config.json'), 'w') as f:\n",
    "                json.dump(config_dict, f, sort_keys=True, indent=4)\n",
    "\n",
    "            config = utilities.config_to_namedtuple(config_dict)\n",
    "            pert_p, coff_p, ind1, ind2, output_p, log_output, area = UniversalPert(sess, config, path_new, batchsize, batchsize2, regul).attack(image, labs, labs2)\n",
    "            print(labs[ind1])\n",
    "            print(labs2[ind2])\n",
    "            #pos_mul.append(output_p)\n",
    "            bestarea_cand_pos.append(pert_p)\n",
    "            out_cand_pos.append(log_output)\n",
    "            area_cand_pos.append(area)\n",
    "\n",
    "\n",
    "        temp_out_poison = []\n",
    "        tf.reset_default_graph()\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.initializers.global_variables())\n",
    "            config_dict = utilities.get_config('config.json')\n",
    "            regul = 'l1'\n",
    "            model_dir = config_dict['model']['output_dir']\n",
    "            if not os.path.exists(model_dir):\n",
    "                os.makedirs(model_dir)\n",
    "\n",
    "            # keep the configuration file with the model for reproducibility\n",
    "            with open(os.path.join(model_dir, 'config.json'), 'w') as f:\n",
    "                json.dump(config_dict, f, sort_keys=True, indent=4)\n",
    "\n",
    "            config = utilities.config_to_namedtuple(config_dict)\n",
    "            image_new = np.reshape(imgs, (batchsize, 32, 32, 3))\n",
    "            lab_new = np.reshape(labs2[0], (1, 10))\n",
    "            pert_single, coff_single, ind_single, output_single = PerImgPert(sess, config, path_new, batchsize, regul).attack(image_new, np.repeat(lab_new, batchsize, axis=0))\n",
    "            pos_single.append(output_single)\n",
    "        for i in range(batchsize):\n",
    "            temp_single = np.dot(output_p[i], np.transpose(output_single[i]))/(np.linalg.norm(output_p[i])*np.linalg.norm(output_single[i]))\n",
    "            temp_out_poison.append(temp_single)\n",
    "        out_save_poison.append(temp_out_poison)\n",
    "        \n",
    "    best_area = np.amin(bestarea_cand_pos)\n",
    "    for cla in range(num_class):\n",
    "        temp_best = np.quantile(out_save_poison[cla], 0.5)\n",
    "        output_p = out_cand_pos[cla]\n",
    "        area = area_cand_pos[cla]\n",
    "        for kk in range(len(area)):\n",
    "            temp_out_poison = []\n",
    "            if area[kk] < 1.1*best_area:        \n",
    "                for i in range(len(pos_single[cla])):\n",
    "                    temp_single = np.dot(output_p[kk][i], np.transpose(pos_single[cla][i]))/(np.linalg.norm(output_p[kk][i])*np.linalg.norm(pos_single[cla][i]))\n",
    "                    temp_out_poison.append(temp_single)\n",
    "                if np.quantile(temp_out_poison, 0.25) > temp_best:\n",
    "                    out_save_poison[cla] = temp_out_poison[:]\n",
    "                    \n",
    "#Save your detection results                    \n",
    "#     res_dir = 'result/'+'pattern'+str(jj+1)+'.pkl'\n",
    "#     with open(res_dir, 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "#         pickle.dump(out_save_poison, f)\n",
    "\n",
    "\n",
    "#check whether the model is a Trojan model and the target label\n",
    "T = 0.75 #a preset threshold\n",
    "target = -1\n",
    "for i in range(10):\n",
    "    if np.quantile(out_save_poison[i], 0.25) > T:\n",
    "        print('The model is a Trojan model and the target label is: {}'.format(i))\n",
    "        target = i\n",
    "if target == -1:\n",
    "    print('The model is a clean model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
